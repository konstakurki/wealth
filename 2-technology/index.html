<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<title>2. Technology</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="author" content="Konsta Kurki" />
<meta name="description" content="" />

<meta property="og:site_name" content="" />
<meta property="og:title" content="" />
<meta property="og:url" content="" />
<meta property="og:description" content="" />
<meta property="og:image" content="" />
<meta property="og:type" content="website" />
<meta property="og:website:author" content="Konsta Kurki" />

<link rel="stylesheet" type="text/css" href="../style.css" />

<script type='text/javascript' src='../nightmode.js'></script>

</head>

<body class='day' onload='lightsOnCookie()'>

<div class='frontpage'>

<div class='nav'><p><a href='../'>Contents</a> | <a href='javascript:void(0)' onclick='lightswitch()'>Night mode</a><!--&nbsp;&nbsp;<a class='os' href='../home-page/'>In English</a>--></p></div>

<main>

<h1 id='2-technology'>2. Technology</h1>

<p><em>Updated on August 6, 2017</em></p>

<ol>
<li><a href='#2-1-revolutions'>Revolutions</a></li>
<li><a href='#2-2-revolution-i-code'>Revolution I: Code</a></li>
<li><a href='#2-3-revolution-ii-machine-learning'>Revolution II: Machine learning</a></li>
<li><a href='#2-4-practise-and-theorems'>Practise and theorems</a></li>
<li><a href='#2-5-decoding-a-magic-trick'>Decoding a magic trick</a></li>
</ol>

<p>Technology, the force that eats jobs, is nothing but ways of arranging things in the world so that humans need to do less, yet results will be better. In short, technology is being smart.</p>

<p>If we, for example, need to move a box full of stuff a few kilometers to another village, we may just drag or carry the box—or we may put circle-like objects, called wheels, under the box, and then drag it. Then we don’t need to keep the box up in the air, nor we need much force for moving it. Wheel is simple, yet incredibly effective technology for moving things around.</p>

<p>What we call high-tech is fundamentally no different from simple technologies like wheel. There may be more moving parts, and the physical phenomena and mathematics exploited may be more exotic, yet it’s always about being smart. There is never magic at play; if there is a feeling of magic, it disappears at the moment you find out how the technology works.</p>

<h2 id='2-1-revolutions'>2.1 Revolutions</h2>

<p>What determines whether a technology is revolutionary or not? The answer is, whether it solves a real problem of human life or not. Here are some real revolutions.</p>

<ul>
<li>Fire solved the problem of how to turn hard food soft. It enabled us to evolve smaller jawbone, freeing space for larger brains??.</li>
<li>Steam engine solved the problem of how to generate physical force without using our muscles. It enable us to build trains, motorized ships and later power plants.</li>
<li> Semiconductors and Turing-complete computer architectures solved the problem of how to build general-purpose information processing machines. It free us from doing well-defined thinking tasks by ourselves.</li>
<li>Internet solved the problem of how to instantaneously send any information between any two places. It allowed us to maintain friendships and work over an arbitrary distance. Modern mobile broadband is capable to stream HD video, which exceeds the human capacity to receive information. Once such Internet reaches every place on Earth, our communication problem is solved for good.</li>
</ul>

<p>Technological hype is a common phenomenon, since it advances sales of new technology. Most often the hype is a bubble and “revolutionary” just isn’t revolutionary. Unjustified hype can be exposed by asking the defining question: does it solve a real problem?</p>

<ul>
<li>Space tourism is not revolutionary, since space is an incredibly dull place.</li>
<li>Computer brain implants are not revolutionary, since smartphones have already plugged us into Internet 24/7.</li>
<li>Hoverboards? are not revolutionary, since we already have legs and bicycles.</li>
</ul>

<!--<h3>Virtual and augmented reality</h3>

<h3>Closed-source software and cloud services</h3>-->

<p>It’s important to recognize false hype, as it is a mind control method by which our decisions are steered towards irrational directions, and it overloads our brains so that we may become blind to technologies that really matter.</p>

<p>Currently there are two real revolutions going on. First, computers and Internet enabled us write code together, as a community. Code is text that makes machines do what we want them to do. When we write code together, we are building a single huge ocean of technology that will eventually solve all our information related problems in such a way that everyone has 100% access to the complete ocean, with no cost or restrictions.</p>

<p>Second, our computers are nowadays so powerful that we have a implementable answer to the question “How to make machines accomplish tasks we don’t have instructions for?”, provided that we know how to measure how well the task has been accomplished. The answer is <em>machine learning</em>. It’s the technology that all state-of-art AI systems use.</p>

<p>The revolutions of code and machine learning are final technological revolutions in the sense that they will free us from all labor. Only development and maintenance jobs will be left, and the fraction that they take off our time approaches 0%.</p>

<p>Also, a third real revolution is coming. It is the revolution of distributed computing.</p>

<h2 id='2-2-revolution-i-code'>2.2 Revolution I: Code</h2>

<p>Technology is knowledge. As such it’s pure information, in principle. To actually use a technology, you need to physically change things in the world, and if we’re talking about traditional technology, doing so may be very expensive. You may need to solder electronic components on a circuit board, or glue pieces of wood together, or something like that.</p>

<p>In the world of code everything is different. All you need to do is to run the code on your computer. In many cases that takes only a fraction of a second and a negligible amount of electricity. Furthermore, once a piece of code has been written, it can be spread all over the world via Internet, again with negligible cost. So, if the authors of the code allow it to be distributed freely, as they do in the case of <em>free software</em> or <em>open source</em>, using code does not cost a thing.</p>

<p>In practise it works like this: if the code you want to use is mature enough, it probably is available in a software repository. If it is, you use the package manager of your system to fetch and install the corresponding package. If I, for example, want to install a program caller <code>cmatrix</code>, I just type <code>sudo apt install cmatrix</code> and hit enter. To run the program, I type <code>cmatrix</code> and hit enter. (How can it be so simple? See <a href='https://en.wikipedia.org/wiki/Package_manager'>Package manager</a> on Wikipedia for more information.) If the code is in a more experimental phase, you can most likely find it on a site like GitHub or GitLab.</p>

<p>Traditionally, testing has been the expensive part of developing a technology. To build a safe car, multiple prototypes must be built and then be destroyed in crash tests. Code can be tested with no costs, and therefore be developed without money. Only time, passion and a little bit of skill is needed.</p>

<p>History confirms that. In 1983 Richard Stallman announced the GNU Project, which aimed to develop a completely free operating system, and in a few years all pieces but the kernel had been written. Then in 1991 Linus Torvalds wrote a free kernel, which is now known as Linux. The combination, which goes by names GNU/Linux, GNU+Linux or just Linux, is a massive success: it is used largely on web servers, supercomputers use it almost exclusively, and Android phones are based on it (or the kernel?). Linux comes in numerous slightly different flavors, for example Debian and Ubuntu.</p>

<p>Community works so well in writing code, because there are so many people in the world. <a href='http://www.phoronix.com/scan.php?page=news_item&px=Linux-19.5M-Stats'>By 2015</a> about 15 thousand people had contributed 19.5 million lines of code to the Linux kernel, which is quite a lot. Those contributors make about two millionth of the world population. In other words, a tiny, tiny fraction of us is enough to write massive amounts of state-of-art code.</p>

<p>When a community writes code, all the pieces become available to everyone, and anyone can build on anyone’s previous work. This truth manifests itself in software libraries, which consist of pieces of code that are intended for use as building blocks of larger programs. Library wraps those pieces in such a way that the user (the person who writes the large program using the library) only needs to learn an API (the interface via the library is accessed). Thanks to libraries, writing serious software is often just connecting existing pieces with relatively few lines of code and little effort.</p>

<p>Information technology shows the exponential nature of tech evolution clearly, as every step taken speeds up the next. In the 80’s co-writing software was sluggish, because interchanging pieces of code had to be done by mechanically transporting media like tape or discette. Internet changed this. Another significant milestone was in 2005, when Linus Torvalds decided to write a free version control system for developing the Linux kernel. He named the software Git. There is a free book, <a href='https://git-scm.com/book/en/v2'><cite>Pro Git</cite></a>, that teaches Git in depth.</p>

<p>Git functions by saving snapshots, or “commits,” of a project as it evolves. The development can be branched (or forked) into several separate development lines of successive commits, which can then be merged back to one. This enables many developers to work simultaneously on one project irrespective of their schedules or geographic locations. Sites like GitHub and GitLab host Git repositories, making it incredibly easy to contribute to an open source project: you find the project at the site, fork it, make your changes, and then request the project maintainers to merge your contribution.</p>

<p>All these steps—GNU, Linux, package managers, libraries, Git—can be seen as points on an exponential curve which pushes the costs—measured in terms of money, time, effort and snapped nerves—of any computing task down to zero.</p>

<!--<p>One of the triumphs of the code revolution is the Python programming language. 



, which hold code instead of text in natural languages. Libraries 

<p>

<ul>
<li>1983: The GNU Project</li>
<li>1991: Linux, WWW, Python</li>
<li>2005: Git</li>
<li>2008: GitHub</li>
<li>


There really is just one software stack that expands and improves all the time.


<h2>The evergrowing stack of lines of code</h2>

<pre><code>print('Hello World!')</code></pre>-->

<h2 id='2-3-revolution-ii-machine-learning'>2.3 Revolution II: Machine learning</h2>

<p>When I grab Rubik’s Cube and solve it, people think I’m an exceptionally intelligent guy. Then I reveal that I’ve just memorized a few move sequences which I use like a machine, and they don’t think so anymore.</p>

<!--<p>If someone solves Rubik’s Cube by just looking at it, we think he or she is an exceptionally intelligent person. If it is then revealed that he or she had memorized all the needed move sequences and just used them like a computer, the appreciation and perception of intelligence goes away.</p>-->

<p>Intelligence is being capable of solving problems without instructions. It’s in a deep conflict with computer programming, since programming means writing precise instructions for computers. Building intelligent machines is notoriously difficult.</p>

<p>We can skip this difficulty by building childlike machines, which then learn to solve problems by themselves. More precisely, we build a mathematical machine with many—like a billion—knobs, which is capable of doing a wide variety of things depending on the knob configuration. Most configurations lead to useless behaviour, yet some may make the machine do something that resembles intelligence.</p>

<p>Mathematical results show that there are very simple mathematical machines that can do virtually anything provided there are enough knobs and that the knobs have been tuned correctly. The tuning, or teaching, can be done by generic optimization algorithms, which means methods for seeking parameter values that result in better and better performance.</p>

<p>In other words, we write code, which contains precise instructions for learning how to get better at the task. “Better” must be defined precisely, which means that it must be possible to measure performance by single number. Machine learning is all about what can be measured numerically.</p>

<p>Let’s take car driving as an example. (CHANGE CAR DRIVING TO WALKING) The task is to keep the car on the road and go forward. We give our machine driver some sensory input, like car’s acceleration, speed and distance to the road shoulders, and the driver must decide how to turn the steering wheel and how much to give gas.</p>

<p>First we let the driver act in a hastened rally simulator instead of real roads, so that the driver can learn quicker, without crushing real cars. Then we decide how to measure performance. A simple way could be to just count how many meters it manages to keep the car on the road. That could work, yet learning would be slow, and the result would probably be stupid driving on a speed that changes along the way.</p>

<p>It would be wiser to compose a score for the last kilometers driven so that the stabler the drive is and the closer to the center of the lane the car has stayed, the better the score. That would make the AI driver to learn properly.</p>

<p>The actual learning happens so that the driver drives the car and constantly monitors the score of the past kilometers. Once in the while the driver makes small random changes to the driving style (the knob configuration) and keeps track on how the changes affect the score. As it collects more experience, it starts to prefer changes that seem to result in better score in the long run. If everything has been done right, after enough kilometers the driving style has converged towards something reasonable, and we can say that the AI driver has learned to drive.</p>

<h2 id='2-4-practise-and-theorems'>2.3 Practise and theorems</h2>

<p>What I described above is called <em>reinforcement learning</em>. It is how humans, animals and whole communities and societies learn new ways to thrive. The fundamental elements are exploring new, unknown ways to act, of which most are obviously unfruitful, and exploiting the information brought by the performance score for moving towards more fruitful policies. There are also learning paradigms called <em>supervised learning</em> and <em>unsupervised learning</em>, which I’ll describe in a moment.</p>

<!--<p>In machine learning there are also <em>supervised learning</em> and <em>unsupervised learning</em> They are not as capable as reinforcement learning, but they are easier to implement. Most successful real-world AI systems use one of them. In supervised learning the learning agent is shown examples and asked to imitate them, and in unsupervised learning the agent is shown data, and is asked to find some underlying structure from it.</p>-->

<p>The amount of training needed increases exponentially?? as we increase the complexity of the problem. If we let the weather and driving conditions vary in the rally simulator, the machine driver must learn to detect when the situation changes and tweak the driving style appropriately. Learning that would take many orders of magnitude greater amount of training than learning a single, fixed way to drive, and lots of learning means lots of computer resources.</p>

<p>I don’t know whether driving in different conditions is too complex task to learn for a machine. Anyway, if we add traffic, including bad, temperamental drivers, and ask to go from an address to another one instead of just going forward, we have created practically unlearnable task, since learning would take a billion times all the computer resources on Earth for the age of the entire Universe, or something like that.</p>

<p>Complex tasks can be addressed by dividing the task into simpler sub-tasks that are learnable. We train several distinct drivers for different weathers and a weather detector to choose which driver to use, and so on. This is just ordinary engineering philosphy: big problems are nothing but a bunch of smaller problems.</p>

<p>Of course, if we customize our system in that way, we can’t expect it to be useful for anything else than the problem we customized it for. This is a manifestation of the “<a href='https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization'>no free lunch theorem</a>,” which states roughly that there is no universal machine learning system that would learn all tasks quickly. Speed can only be achieved by customization.</p>

<p>Humans and other animals are highly specified learners. Walking, talking and our complex set of emotion are all skills we learn during our first years, yet the ability to learn them is encoded in our DNA molecule. It has taken millions of years for evolution to find the genes that enable us to learn those things. It is physically impossible to teach a chimpanzee to be empathic in a humane way.</p>

<p>The no free lunch theorem is why people talk about deep neural networks today. First, “neural network” in machine learning refers to a mathematical machine which has been inspired by biological brains. A brain is a network of neurons connected to each other. A neuron computes chemically the weighted average of its inputs, applies a simple activation function (something like tanh(<i>x</i>) ??), and outputs the result. The weight factors are the knobs to be tuned in learning.</p>

<p>The <a href='https://en.wikipedia.org/wiki/Universal_approximation_theorem'>universal approximation theorem</a> states that a particular kind of neural network can approximate any continuous function that maps a bunch of numbers into a bunch of numbers. It can there fore do anything, so to speak. Anyway, such a simple neural network is difficult to teach to do most interesting problems. It has been noticed that by cascading several simple networks as a multilayer network, of course in carefully chosen, problem-specific ways, complex tasks can be made learnable. The word “deep” means that there are several (for example ten) stacked layers in a network.</p>

<p>Learning machine learning is not as difficult as it sounds like. Common sense takes far, and the math is much easier than in physics, for example. There are great web resources available: <a href='http://www.deeplearningbook.org/'><cite>Deep Learning</cite></a> by Goodfellow, Bengio and Courville teaches modern supervised and unsupervised learning, and <a href='http://incompleteideas.net/sutton/book/the-book.html'><cite>Reinforcement Learning: An Introduction</cite></a> by Sutton and Barto teaches modern reinforcement learning.<p>

<p>Machine learning also contributes to the code revolution: there are <a href='https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software'>numerous</a> free libraries for writing machine learning applications. These include TensorFlow, the cutting-edge AI library used and developed by Google.</p>

<h2 id='2-5-decoding-a-magic-trick'>2.5 Decoding a magic trick</h2>

<p>Artificial intelligence is a thoroughly mystified subject. The reason is obvious: at first glance, the results of modern AI experiments look like that a supernatural spirit has taken over a computer—at least if someone else happens to suggest such a pseudo-explanation.</p>

<p>I must confess that I’ve been terrified by artificial intelligence in the past. That was the reason I started learning AI, as I wanted to work out my obviously irrational emotional state. I found a solid theory that makes perfect sense and leaves no room for mysticism. It’s now evident that if I had only made my own conclusions, I would never have been terrified. My irrational emotional state was crafted by tabloids and statements by corrupt AI experts, who want the subject to remain mysterious, as it helps them to maintain a status of god.</p>

<p>It’s the same as stage magic. A magician performs a trick, which seems impossible, and by his or her body language, words and clothing makes the audience feel a presence of the supernatural. Then someone ruins the trick by explaining it, and the supernatural disappears. Of course! How could I be so stupid.</p>

<p>I’ll now ruin some AI tricks. First, a <a href='http://cs.stanford.edu/people/karpathy/deepimagesent/'>machine that explains what happens in a picture</a> (2015). For example, there’s a picture in which a man in black shirt is playing guitar, and the machine writes, “man in black shirt is playing guitar.” Obviously, there’s a supernatural spirit grown inside the machine, consciously trying to prove humans it, or he, or she understands.</p>

<p>The trick is that they used supervised learning and huge sets of images with labels written by humans for training. For example the <a href='http://mscoco.org/'>COCO</a> dataset they used contains 2.5 million labeled instances in 328 thousand images. It took 70,000 hours of human work to create the dataset.</p>

<p>So the machine does not understand what the images contain. Instead, its parameter configuration contains information of typical shapes in the pictures and the words people use for describing them. Errors in <a href='http://cs.stanford.edu/people/karpathy/deepimagesent/generationdemo/'>captions written by the machine</a> reveal that the machine is just a machine: for a picture portraying a baseball cap it writes “a pair of scissors with a pair of scissors.”</p>

<p>This kind of AI copies the knowledge that is included in the training examples. The same principle is used for training machines to create art. Of course, such machines don’t create real art, since art is expressing emotions, which the machines trained that way don’t have.</p>

<p>Second, a machine that the <cite>Wired</cite> magazine <a href='https://www.wired.com/2012/06/google-x-neural-network/'>described</a> on June 26, 2012 as following:</p>

<blockquote>When computer scientists at Google’s mysterious X lab built a neural network of 16,000 computer processors with one billion connections and let it browse YouTube, it did what many web users might do—it began to look for cats.</blockquote>

<p><a href='https://arxiv.org/abs/1112.6209'>The research paper</a> explains what really happened. The researchers used unsupervised training and a deep so-called sparse autoencoder network, which they trained using 10 milloin random screenshots of YouTube videos. “Autoencoder” means a network, which is supposed to output almost the same data as is shown to its inputs, and “sparse” means that in the middle layers only some neurons output a non-zero value. Technically, the performance measure is a combination of how close the output is the input and how close to zero most middle neurons are.</p>

<p>The idea of sparse autoencoder is to compress the data that goes through it. As the network is trained, individual middle neurons converge to indicate the presence of different features that occur in the data, while the rest of the network learns to reconstruct those features. In the experiment one of the middle neurons converged to correlate with the presence of a cat with 74.8% accuracy. There was also a neuron that detected human faces with 81.7% accuracy and a neuron that detected human bodies with 76.7% accuracy. The obvious explanation is that cats, human faces and human bodies are common features of YouTube videos.</p>

<p><cite>Wired</cite> partly explains this later in their article. I quoted its first paragraph, because it’s a good example of a mystifying unexplanation that pollute statements about artificial intelligence.</p>

<p>Then, third and final trick: a <a href='https://arxiv.org/abs/1312.5602'>machine that plays Atari 2600</a> (2013). Researchers used reinforcement learning to train a deep neural network with screen pixels fed to its inputs and the game controller connected to its outputs to play seven old Atari 2600 video games (although not at the same time; the network had to be trained separately for each game). The machine beat a human expert in three games: Breakout, Enduro and Pong.</p>

<p>The performance measure op: the ordinary score of the game that 

<h2>2.6 Machines will learn our jobs</h2>

<h2>2.3 Revolution III: Distributed computing</h2>

</main>

<div class='nav'><p><a href='../'>Contents</a> | <a href='javascript:void(0)' onclick='lightswitch()'>Night mode</a><!--&nbsp;&nbsp;<a class='os' href='../home-page/'>In English</a>--></p></div>

<hr />

<p>Copyright &copy; 2017 Konsta Kurki</p>

<p>This page is licensed under <a href='https://creativecommons.org/licenses/by-sa/4.0/'>CC BY-SA 4.0</a>.</p>

</body>

</html>
